# VAST AI Research - Complete Research Projects

- **[MIDI-3D](https://github.com/VAST-AI-Research/MIDI-3D)**: [CVPR 2025] Multi-Instance Diffusion for Single Image to 3D Scene Generation [[Code]](https://github.com/VAST-AI-Research/MIDI-3D)
- **[Deformable Radial Kernel Splatting](https://github.com/VAST-AI-Research/Deformable-Radial-Kernel-Splatting)**: [CVPR 2025] Extending Gaussian Splatting into a More General and Flexible Framework [[Code]](https://github.com/VAST-AI-Research/Deformable-Radial-Kernel-Splatting)
- **[PSHuman](https://penghtyx.github.io/PSHuman/)**: [CVPR 2025] Photorealistic Single-image 3D Human Reconstruction using Cross-Scale Multiview Diffusion and Explicit Remeshing [[Code]](https://github.com/pengHTYX/PSHuman)
- **[DI-PCG](https://thuzhaowang.github.io/projects/DI-PCG/)**: [CVPR 2025] Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation [[Code]](https://github.com/TencentARC/DI-PCG)
- **[TEXGen](https://cvmi-lab.github.io/TEXGen/)**: [SIGGRAPH Asia 2024] A Generative Diffusion Model for Mesh Textures (**Best Paper Honorable MentionðŸŽ‰**) [[Code]](https://github.com/CVMI-Lab/TEXGen)
- **[Splatter a Video](https://sunyangtian.github.io/spatter_a_video_web/)**: [NeurIPS 2024] Video Gaussian Representation for Versatile Processing [[Code]](https://github.com/SunYangtian/Splatter_A_Video)
- **[HiFi-123](https://drexubery.github.io/HiFi-123/)**: [ECCV 2024] Towards High-fidelity One Image to 3D Content Generation [[Code]](https://github.com/AILab-CVC/HiFi-123)
- **[DreamDiffusion](https://github.com/bbaaii/DreamDiffusion)**: [ECCV 2024] Generating High-Quality Images from Brain EEG Signals [[Code]](https://github.com/bbaaii/DreamDiffusion)
- **[GVGEN](https://sotamak1r.github.io/gvgen/)**: [ECCV 2024] Text-to-3D Generation with Volumetric Representation [[Code]](https://github.com/SOTAMak1r/GVGEN)
- **[UniDream](https://yg256li.github.io/UniDream/)**: [ECCV 2024] Unifying Diffusion Priors for Relightable Text-to-3D Generation [[Project Page]](https://yg256li.github.io/UniDream/)
- **[DMiT](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07243.pdf)**: [ECCV 2024] Deformable Mipmapped Tri-Plane Representation for Dynamic Scenes
- **[CharacterGen](https://charactergen.github.io/)**: [SIGGRAPH 2024] Efficient 3D Character Generation from Single Images [[Code]](https://github.com/zjp-shadow/CharacterGen)
- **[TriplaneGaussian](https://github.com/VAST-AI-Research/TriplaneGaussian)**: [CVPR 2024] A new hybrid representation for single-view 3D generation [[Code]](https://github.com/VAST-AI-Research/TriplaneGaussian)
- **[EpiDiff](https://huanngzh.github.io/EpiDiff/)**: [CVPR 2024] Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion [[Code]](https://github.com/huanngzh/EpiDiff)
- **[Wonder3D](https://www.xxlong.site/Wonder3D/)**: [CVPR 2024] Single Image to 3D using Cross-Domain Diffusion [[Code]](https://github.com/xxlong0/Wonder3D)
- **[DreamComposer](https://yhyang-myron.github.io/DreamComposer/)**: [CVPR 2024] Controllable 3D Object Generation via Multi-View Conditions [[Code]](https://github.com/yhyang-myron/DreamComposer)
- **[SC-GS](https://yihua7.github.io/SC-GS-web/)**: [CVPR 2024] Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes [[Code]](https://github.com/yihua7/SC-GS)
- **[PI3D](https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_PI3D_Efficient_Text-to-3D_Generation_with_Pseudo-Image_Diffusion_CVPR_2024_paper.pdf)**: [CVPR 2024] Efficient Text-to-3D Generation with Pseudo-Image Diffusion
- **[CSD](https://xinyu-andy.github.io/Classifier-Score-Distillation/)**: [ICLR 2024] Text-to-3D with Classifier Score Distillation [[Code]](https://github.com/CVMI-Lab/Classifier-Score-Distillation)
- **[3DGS Survey](https://arxiv.org/abs/2403.11134)**: [CVMJ] Recent Advances in 3D Gaussian Splatting
- **[MV-Adapter](https://huanngzh.github.io/MV-Adapter-Page/)**: Multi-view Consistent Image Generation Made Easy [[Code]](https://github.com/huanngzh/MV-Adapter)
- **[SAMPart3D](https://yhyang-myron.github.io/SAMPart3D-website/)**: Segment Any Part in 3D Objects [[Code]](https://github.com/Pointcept/SAMPart3D)
- **[OctFusion](https://arxiv.org/abs/2408.14732)**: Octree-based Diffusion Models for 3D Shape Generation [[Code]](https://github.com/octree-nn/octfusion)
- **[DreamCraft3D++](https://dreamcraft3dplus.github.io/)**: Efficient Hierarchical 3D Generation with Multi-Plane Reconstruction Model [[Code]](https://github.com/MrTornado24/DreamCraft3D_Plus)
- **[MeshCraft](https://arxiv.org/abs/2503.23022)**: Exploring Efficient and Controllable Mesh Generation with Flow-based DiTs
- **[SuperMat](https://hyj542682306.github.io/SuperMat/)**: Physically Consistent PBR Material Estimation at Interactive Rates
- **[DetailGen3D](https://detailgen3d.github.io/DetailGen3D/)**: Generative 3D Geometry Enhancement via Data-Dependent Flow 
- **[SparseFlex](https://xianglonghe.github.io/TripoSF/)**: High-Resolution and Arbitrary-Topology 3D Shape Modeling (TripoSF) [[Code]](https://github.com/VAST-AI-Research/TripoSF)